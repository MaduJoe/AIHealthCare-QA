import warnings

# Suppress FutureWarnings
warnings.simplefilter(action='ignore', category=FutureWarning)

from flask import Flask, request, jsonify
from transformers import AutoFeatureExtractor, AutoModelForImageClassification
from PIL import Image
import torch
import io
import time
import os
from health_check import add_health_endpoint

app = Flask(__name__)

# ê±´ê°• ì²´í¬ ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
add_health_endpoint(app)

MODEL_NAME = os.environ.get("MODEL_NAME", "google/vit-base-patch16-224")

print(f"ëª¨ë¸ ë¡œë”© ì‹œì‘: {MODEL_NAME}")
extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)
model = AutoModelForImageClassification.from_pretrained(MODEL_NAME)
print("ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {device}")
model.to(device)
model.eval()

@app.route("/analyze", methods=["POST"], strict_slashes=False)
def analyze_image():
    start_time = time.time()

    if "file" not in request.files:
        print("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")  # ğŸ”¥ ë””ë²„ê·¸ìš© ì¶œë ¥
        return jsonify({"status": "error", "message": "No file uploaded"}), 400

    file = request.files["file"]
    print(f"ì—…ë¡œë“œëœ íŒŒì¼ ì´ë¦„: {file.filename}")  # ğŸ”¥ ë””ë²„ê·¸ìš© ì¶œë ¥

    try:
        image = Image.open(io.BytesIO(file.read())).convert("RGB")
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {e}")  # ğŸ”¥ ë””ë²„ê·¸ìš© ì¶œë ¥
        return jsonify({"status": "error", "message": "Failed to process image"}), 400

    inputs = extractor(images=image, return_tensors="pt").to(device)

    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        pred_class_idx = probs.argmax(dim=1).item()
        confidence = probs[0, pred_class_idx].item()
        print(f"confidence: {confidence}")
    predicted_label = model.config.id2label[pred_class_idx]

    # ê²°ê³¼ ìƒì„±
    abnormality_score = int(confidence * 100)
    flags = [predicted_label.lower()]

    response = {
        "status": "success",
        "model_type": "huggingface",
        "processing_time_ms": round((time.time() - start_time) * 1000, 2),
        "result": {
            "abnormality_score": abnormality_score,
            "confidence": confidence,
            "flags": flags
        }
    }

    return jsonify(response), 200

@app.route("/analyze/error", methods=["POST"], strict_slashes=False)
def simulate_error():
    """
    ì˜¤ë¥˜ ì‹œë®¬ë ˆì´ì…˜ ì—”ë“œí¬ì¸íŠ¸
    í…ŒìŠ¤íŠ¸ì—ì„œ ì˜¤ë¥˜ ì²˜ë¦¬ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    return jsonify({
        "status": "error",
        "message": "Internal server error simulation",
        "error_code": "INTERNAL_ERROR"
    }), 500

@app.route("/analyze/metadata", methods=["GET"], strict_slashes=False)
def get_model_metadata():
    """
    ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì œê³µ ì—”ë“œí¬ì¸íŠ¸
    FDAì™€ ISO13485 ê·œì œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ê¸° ìœ„í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    return jsonify({
        "version": "1.0.0",
        "regulatory_status": "FDA cleared",
        "intended_use": "Chest X-ray abnormality detection",
        "sensitivity": 0.95,
        "specificity": 0.92,
        "last_updated": "2024-05-01",
        "model_id": "lunit-care-qa-v1",
        "model_type": "huggingface",
        "base_model": MODEL_NAME
    }), 200

@app.route("/", methods=["GET"], strict_slashes=False)
def index():
    """
    ê¸°ë³¸ ì—”ë“œí¬ì¸íŠ¸
    ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì„ì„ ë‚˜íƒ€ë‚´ëŠ” ê¸°ë³¸ ì‘ë‹µì…ë‹ˆë‹¤.
    """
    return jsonify({
        "service": "LunitCare QA Mock API Server",
        "version": os.environ.get("SERVICE_VERSION", "development"),
        "endpoints": ["/analyze", "/health", "/analyze/error", "/analyze/metadata"]
    }), 200

# ì´ë ‡ê²Œ í•˜ë©´ /analyze ëŒ€ì‹  ë” ê°€ë²¼ìš´ APIë¡œ í™•ì¸ ê°€ëŠ¥:
@app.route("/healthz")
def health_check():
    return "ok", 200

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    host = os.environ.get("HOST", "0.0.0.0")
    debug = os.environ.get("DEBUG", "False").lower() == "true"
    
    print(f"ì„œë²„ ì‹œì‘: {host}:{port} (ë””ë²„ê·¸: {debug})")
    app.run(host=host, port=port, debug=debug)